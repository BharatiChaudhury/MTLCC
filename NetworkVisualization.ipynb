{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Visualization\n",
    "\n",
    "This notebook loads a dataset and network and visualized the dataset features and subsequent network activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from Dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "# custom functions for interactiva plotting\n",
    "from utils.interactive_plotting import show, show_gray, show_rgb\n",
    "# custom functions for writing pngs\n",
    "from utils.interactive_plotting import norm_ptp, norm_std, norm_rgb, write, dump3, dump, dump_rgb, dump_class\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "modeldir=\"data_IJGI18/models/convlstm256_48px\"\n",
    "\n",
    "# None -> dont write output pngs\n",
    "outfolder=None\n",
    "\n",
    "datadir=\"data_IJGI18/datasets/demo/480\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataset\n",
    "\n",
    "If `RessourceExhaustedError` or `OutOfMemory` error occur later: reduce number ids in `overwrite_ids` and `batchsize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set specificly which ids should be returned (set none for random)\n",
    "# tile ids from paper: 1823 8133 2550 2554 10791 10792 10879 10969 12894 16494 1272\n",
    "overwrite_ids=[2550,10969]\n",
    "batchsize=2\n",
    "\n",
    "dataset = Dataset(datadir=datadir, \n",
    "                  verbose=True, \n",
    "                  temporal_samples=None, \n",
    "                  section=\"2016\")\n",
    "\n",
    "tfdataset, _, _, filenames = dataset.create_tf_dataset(\"eval\",0,batchsize,True,2,overwrite_ids=overwrite_ids)\n",
    "iterator = tfdataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TF Session and initialize iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "data_handle = sess.run(iterator.string_handle())\n",
    "\n",
    "#train_writer = tf.summary.FileWriter(os.path.join(args.modeldir, TRAINING_SUMMARY_FOLDER_NAME), sess.graph)\n",
    "#test_writer = tf.summary.FileWriter(os.path.join(args.modeldir, TESTING_SUMMARY_FOLDER_NAME))\n",
    "\n",
    "sess.run([iterator.initializer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout input data from the iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run([tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "# run a network session with the operations defined prviously\n",
    "x10,x20,x60,doy,year,labels = sess.run(iterator.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rgb(x10)\n",
    "show_rgb(x20)\n",
    "show_rgb(x60)\n",
    "show_gray(labels[:,0,:,:],name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model graph definition (graph.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=os.path.join(modeldir,\"graph.meta\")\n",
    "tf.train.import_meta_graph(graph)\n",
    "\n",
    "# initialize variables\n",
    "sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore weights from checkpoint (model.ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(save_relative_paths=True)\n",
    "checkpoint = os.path.join(modeldir, \"model.ckpt\")\n",
    "\n",
    "latest_ckpt = tf.train.latest_checkpoint(modeldir)\n",
    "if latest_ckpt is not None:\n",
    "    print \"restoring from \" + latest_ckpt\n",
    "    saver.restore(sess, latest_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all available operations within the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph.get_operations()\n",
    "# tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve operations from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_op(name):\n",
    "    return tf.get_default_graph().get_operation_by_name(name).outputs[0]\n",
    "\n",
    "## get variables from tf.default_graph\n",
    "iterator_handle_op = get_op(\"data_iterator_handle\")\n",
    "is_train_op = get_op(\"is_train\")\n",
    "global_step_op = get_op(\"global_step\")\n",
    "train_op = get_op(\"train_op\")\n",
    "\n",
    "# container to store operations to be obtained\n",
    "query_map=dict()\n",
    "\n",
    "#atrousdeep generation\n",
    "query_map[\"x\"]=\"input/reshaped/x\"\n",
    "\n",
    "query_map[\"convrnn_input\"]=\"convrnn1/input\"\n",
    "query_map[\"convrnn_output\"]=\"convrnn1/outputs\"\n",
    "query_map[\"convrnn_state\"]=\"convrnn1/final_states\"\n",
    "    \n",
    "query_map[\"targets\"]=\"targets\"\n",
    "query_map[\"predictions\"]=\"predictions\"\n",
    "query_map[\"prediction_scores\"]=\"prediction_scores\"\n",
    "query_map[\"correctly_predicted\"]=\"correctly_predicted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference - Execute the graph with data and store results in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = {iterator_handle_op:data_handle,is_train_op:False}\n",
    "\n",
    "operations = ops = [get_op(query_map[key]) for key in sorted(query_map.keys())]\n",
    "\n",
    "# run a network session with the operations defined prviously\n",
    "queried = sess.run(operations,feed_dict=feed)\n",
    "\n",
    "# build a results dict\n",
    "results=dict()\n",
    "for key, array in zip(sorted(query_map.keys()),queried):\n",
    "    results[key]=array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rgb(results[\"x\"], name=\"x\")\n",
    "show_gray(results[\"targets\"],name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence encoder input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(results[\"convrnn_input\"],name=\"convrnn_in\")\n",
    "show(results[\"convrnn_state\"],name=\"states\")\n",
    "\n",
    "if outfolder is not None:\n",
    "    dump3(array=results[\"convrnn_state\"], name=\"final_state\", outfolder=outfolder, cmap=\"inferno\")\n",
    "    dump3(array=results[\"prediction_scores\"], name=\"prediction_scores\", outfolder=outfolder, cmap=\"inferno\")\n",
    "#dump(array=results[\"convrnn_state\"], name=\"final_state\", outfolder=outfolder, cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations for each class (aka band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gray(results[\"prediction_scores\"],name=\"prediction scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gray(results[\"predictions\"],name=\"predictions\",vmin=0,vmax=26)\n",
    "show_gray(results[\"targets\"],name=\"labels\",vmin=0,vmax=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate LSTM iteration to access gate activations\n",
    "\n",
    "also implemented in activations.py\n",
    "\n",
    "try:\n",
    "```\n",
    "python activations.py --help\n",
    "```\n",
    "for more info\n",
    "\n",
    "### Define the LSTM cell\n",
    "see implementation in ```utils/convrnn/cell.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.convrnn as convrnn\n",
    "import numpy as np\n",
    "\n",
    "b,t,px,px,d_in = results[\"convrnn_input\"].shape\n",
    "\n",
    "def convolution(inputs,W,data_format):\n",
    "    \"\"\"wrapper around tf.nn.convolution with custom padding\"\"\"\n",
    "    pad_h = int(W.get_shape()[0])/2\n",
    "    pad_w = int(W.get_shape()[1])/2\n",
    "\n",
    "    paddings = tf.constant([[0, 0], [pad_h,pad_h], [pad_w,pad_w], [0, 0]])\n",
    "\n",
    "    inputs_padded = tf.pad(inputs, paddings, \"REFLECT\")\n",
    "\n",
    "    return tf.nn.convolution(inputs_padded, W, 'VALID', data_format=data_format)\n",
    "\n",
    "def layer_norm(inputs,beta,gamma):\n",
    "    \"\"\"taken from contrib tf.contrib.layers.layer_norm definition in\n",
    "    tensorflow/contrib/layers/python/layers/layers.py\n",
    "    \"\"\"\n",
    "    mean, variance = tf.nn.moments(inputs, [1,2,3], keep_dims=True)\n",
    "    outputs = tf.nn.batch_normalization(\n",
    "        inputs, mean, variance, offset=beta, scale=gamma,\n",
    "        variance_epsilon=1e-12)\n",
    "    return outputs\n",
    "\n",
    "x = results[\"convrnn_input\"][:,0]\n",
    "\n",
    "scope = \"convrnn1/bidirectional_rnn/fw/conv_lstm_cell\"\n",
    "\n",
    "\n",
    "#state = sess.run(zero_state_op)\n",
    "\n",
    "weights=[]\n",
    "weights.append(get_op(scope+\"/kernel\"))\n",
    "#weights.append(get_op(scope+\"/W_ci\")) # peephole\n",
    "#weights.append(get_op(scope+\"/W_cf\")) # peephole\n",
    "#weights.append(get_op(scope+\"/W_co\")) # peephole\n",
    "weights.append(get_op(scope+\"/LayerNorm/beta\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm/gamma\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_1/beta\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_1/gamma\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_2/beta\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_2/gamma\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_3/beta\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_3/gamma\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_4/beta\"))\n",
    "weights.append(get_op(scope+\"/LayerNorm_4/gamma\"))\n",
    "\n",
    "def lstm(x,state,weights, peephole=False, activation=tf.nn.tanh):\n",
    "    \"\"\"Implementation modified from carlthome/tensorflow-convlstm-cell\"\"\"\n",
    "\n",
    "    if peephole:\n",
    "        kernel, W_ci, W_cf, W_co, b_j, g_j, b_i, g_i, b_f, g_f, b_o, g_o, b_c, g_c = weights\n",
    "    if not peephole:\n",
    "        kernel, b_j, g_j, b_i, g_i, b_f, g_f, b_o, g_o, b_c, g_c = weights\n",
    "    \n",
    "    \n",
    "    c,h = state\n",
    "    x = tf.concat([x, h], axis=3).eval()\n",
    "    n = x.shape[-1]\n",
    "    m = 4 * convfilters if convfilters > 1 else 4\n",
    "    y = convolution(x,kernel,data_format=\"NHWC\").eval()\n",
    "    #y = tf.nn.convolution(x, kernel, 'SAME', data_format=\"NHWC\").eval()\n",
    "    j, i, f, o = tf.split(y, 4, axis=3)\n",
    "\n",
    "    if peephole:\n",
    "        # peephole connections\n",
    "        i += W_ci * c\n",
    "        f += W_cf * c\n",
    "\n",
    "    # normalize\n",
    "    # replacement for tf.contrib.layers.layer_norm(j)\n",
    "    #\n",
    "    ## normalize in cell.py\n",
    "    #j = tf.contrib.layers.layer_norm(j)\n",
    "    #i = tf.contrib.layers.layer_norm(i)\n",
    "    #f = tf.contrib.layers.layer_norm(f)\n",
    "    #\n",
    "    j = layer_norm(j,b_j,g_j)\n",
    "\n",
    "    i = layer_norm(i,b_i,g_i)\n",
    "\n",
    "    f = layer_norm(f,b_f,g_f)\n",
    "\n",
    "    forget_bias=1\n",
    "    f = tf.sigmoid(f + forget_bias)\n",
    "    i = tf.sigmoid(i)\n",
    "    c = c * f + i * activation(j)\n",
    "    \n",
    "    if peephole:\n",
    "        o += W_co * c\n",
    "\n",
    "    o = layer_norm(o,b_o,g_o)\n",
    "\n",
    "    c = layer_norm(c,b_c,g_c)\n",
    "\n",
    "    o = tf.sigmoid(o)\n",
    "    h = o * activation(c)\n",
    "\n",
    "    state = tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "\n",
    "    return h,state,j,i,f,o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"convrnn_output\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Iteration on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = results[\"convrnn_input\"]\n",
    "\n",
    "b,t,px,px,d = results[\"convrnn_output\"].shape\n",
    "convfilters = d/2\n",
    "zero_state_op = tf.contrib.rnn.LSTMStateTuple(c=tf.zeros(tf.TensorShape([b, px, px, convfilters])),h=tf.zeros(tf.TensorShape([b, px, px, convfilters])))\n",
    "state=sess.run(zero_state_op)\n",
    "\n",
    "jGate = []\n",
    "iGate = []\n",
    "fGate = []\n",
    "oGate = []\n",
    "outputs = []\n",
    "states = []\n",
    "statesh = []\n",
    "\n",
    "# execute on cpu because ressource exhausted error on GPU\n",
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    for time in range(0,t):\n",
    "        print(\"time {}\".format(time))\n",
    "\n",
    "        h,state,j,i,f,o = lstm(inputs[:,time],state, weights)\n",
    "        state = tf.contrib.rnn.LSTMStateTuple(c=state.c.eval(),h=state.h.eval())\n",
    "\n",
    "        #show_gray(i.eval(),\"input_gate at t{}\".format(it))\n",
    "\n",
    "        iGate.append(i.eval())\n",
    "        jGate.append(j.eval())\n",
    "        fGate.append(f.eval())\n",
    "        oGate.append(o.eval())\n",
    "        outputs.append(h.eval())\n",
    "        states.append(state.c)\n",
    "        statesh.append(state.h)\n",
    "\n",
    "iGate = np.stack(iGate,axis=1)\n",
    "jGate = np.stack(jGate,axis=1)\n",
    "fGate = np.stack(fGate,axis=1)\n",
    "oGate = np.stack(oGate,axis=1)\n",
    "outputs = np.stack(outputs,axis=1)\n",
    "states = np.stack(np.array(states),axis=1)\n",
    "statesh = np.stack(np.array(statesh),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "def show_activations(arrays_tuple, titles=[\"\"]):\n",
    "    \n",
    "    max_b, max_t,_,_,max_d = arrays_tuple[1].shape\n",
    "    max_d=10\n",
    "        \n",
    "    def _show_map_BTHWD(t,d,b): \n",
    "        n = len(arrays_tuple)\n",
    "        \n",
    "        fig,axs = plt.subplots(1,n,figsize=(16,6))\n",
    "        \n",
    "        for array,ax,title in zip(arrays_tuple,axs,titles): \n",
    "            ax.imshow(array[b,t,:,:,d-1:d+2])\n",
    "            ax.set_title(title)\n",
    "            #_show(array[b,t,:,:,d],\"{name} feature map b={b}, t={t}, d={d}\".format(name=name,b=b,t=t,d=d))\n",
    "    \n",
    "    # all\n",
    "    b_slider = widgets.IntSlider(description='batch',min=0,max=max_b-1,step=1,value=max_b/2)\n",
    "         \n",
    "    d_slider = widgets.IntSlider(description='band',min=1,max=max_d-1,step=1,value=max_d/2) \n",
    "    t_slider = widgets.IntSlider(description='time',min=0,max=max_t-1,step=1,value=max_t/2)\n",
    "    w = interactive(_show_map_BTHWD, t=t_slider, d=d_slider, b=b_slider)\n",
    "    \n",
    "    w.layout.height = '400px'\n",
    "    display(w)\n",
    "   \n",
    "#show(,\"x\")\n",
    "def norm(arr,thresmin=-1,thresmax=1):\n",
    "    arr[arr<thresmin]=thresmin\n",
    "    arr[arr>thresmax]=thresmax\n",
    "    return ( (arr-arr.min()) / (arr-arr.min()).max()).astype('float')\n",
    "\n",
    "show_activations([iGate,oGate,norm(jGate),fGate,norm(states),norm(statesh),norm(outputs)],titles=[\"i\",\"o\",\"j\",\"f\",\"state\",\"stateh\",\"output\"])\n",
    "show(results[\"x\"])\n",
    "show_gray(states)\n",
    "show_gray(statesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rgb(results[\"x\"], name=\"x\")\n",
    "show_gray(iGate,\"input\")\n",
    "show_gray(fGate,\"forget\")\n",
    "show_gray(states,\"states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Arrays to png files\n",
    "\n",
    "folder structure\n",
    "``\n",
    "{outfolder}/sample{s}/time{t}/{d}_{name}.png\n",
    "``\n",
    "\n",
    "with `s` as sample in batch, `t` as time, `d` as number of feature map and `name` `iGate`,`jGate`,`oGate`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outfolder is not None:\n",
    "\n",
    "    cmap=\"inferno\"\n",
    "\n",
    "    dump_rgb(results[\"x\"][:,:,:,:,0:3],\"x\",outfolder,stddev=4)\n",
    "\n",
    "    dump(array=iGate, name=\"iGate\", outfolder=outfolder, cmap=\"inferno\")\n",
    "    dump(array=fGate, name=\"fGate\", outfolder=outfolder, cmap=\"inferno\")\n",
    "    dump(array=oGate, name=\"oGate\", outfolder=outfolder, cmap=\"inferno\")\n",
    "    dump(array=(jGate/2)+0.5, name=\"jGate\", outfolder=outfolder, cmap=\"RdBu_r\")\n",
    "    dump(array=(statesh/2)+0.5, name=\"output\", outfolder=outfolder, cmap=\"RdBu_r\")\n",
    "    dump(array=(states/2)+0.5, name=\"state\", outfolder=outfolder, cmap=\"RdBu_r\")\n",
    "\n",
    "    dump_class(results[\"targets\"],\"ground_truth\",outfolder)\n",
    "    dump_class(results[\"predictions\"],\"predictions\",outfolder)\n",
    "    for i in range(0,17):\n",
    "        dump_class(results[\"prediction_scores\"][:,:,:,i],\"prediction_scores_\"+str(i),outfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"prediction_scores\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_gradients(name, filename=\"tmp/test.png\",w=8,h=2):\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(w,h)\n",
    "    #fig.subplots_adjust(top=0.95, bottom=0.01, left=0.2, right=0.99)\n",
    "\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    ax.imshow(gradient, aspect='auto', cmap=plt.get_cmap(name))\n",
    "\n",
    "    ax.set_axis_off()\n",
    "        \n",
    "    plt.savefig(filename)\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "if not os.path.exists(\"tmp\"):\n",
    "    os.makedirs(\"tmp\")\n",
    "\n",
    "plot_color_gradients(\"inferno\", w=12,h=3,filename=os.path.join(\"tmp\",\"inferno.png\"))\n",
    "plot_color_gradients(\"RdBu\", w=12,h=3,filename=os.path.join(\"tmp\",\"RdBu.png\"))\n",
    "plot_color_gradients(\"RdBu_r\", w=12,h=3,filename=os.path.join(\"tmp\",\"RdBu_r.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MTLCC]",
   "language": "python",
   "name": "conda-env-MTLCC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
