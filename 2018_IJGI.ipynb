{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - IJGI_2018\n",
    "\n",
    "For http://www.mdpi.com/journal/ijgi Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as skmetrics\n",
    "from os.path import join\n",
    "\n",
    "#path=\"/media/data/marc/eval/fields/convgru128\"\n",
    "#path=\"/media/data/marc/eval/2018_IJGI/convlstm256_48px/eval\"\n",
    "\n",
    "datafolder=\"data_IJGI18\"\n",
    "model24px=\"convgru256\"\n",
    "model48px=\"convgru256_48px\"\n",
    "\n",
    "write_flag=False\n",
    "\n",
    "#path=\"data/bavaria/models/fine_tuned/convgru256/eval\"\n",
    "quantevalpath=join(datafolder,\"eval\",\"full\",model24px) # 'full' or 'demo'\n",
    "qualevalpath=join(datafolder,\"eval\",\"demo\",model48px)  # 'full' or 'demo'\n",
    "\n",
    "docpath=join(datafolder,\"doc\")\n",
    "\n",
    "dat = np.loadtxt(join(quantevalpath,\"2016\",\"classes.csv\"),dtype=str, delimiter=',')\n",
    "ids = [int(id) for id in dat[:,0]]\n",
    "names = classes = dat[:,1]\n",
    "\n",
    "colarray = [[0,101,189],[0, 0, 0],[79,76,76],[0,82,147],[152,198,234],[100,160,200],[218,215,203],[162,173,0],[227,114,34],[105,8,90],[15,27,95],[0,119,138],[0,124,48],[103,154,29],[255,220,0],[249,186,0],[214,76,19],[196,72,27],[156,13,22]]\n",
    "tumcolors=np.array([np.array(col+[255],dtype=float)/255 for col in colarray*10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satellite Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "fn = join(\"data_IJGI18\",\"observations.csv\")\n",
    "# from db (to file)\n",
    "if False:\n",
    "    import psycopg2\n",
    "    with open(os.path.join(os.environ[\"HOME\"],\".pgpass\"),'r') as f:\n",
    "        pgpass = f.readline().replace(\"\\n\",\"\")\n",
    "    host, port, db, user, password = pgpass.split(':')\n",
    "    conn = psycopg2.connect('postgres://{}:{}@{}/{}'.format(user,password,host,db))\n",
    "\n",
    "    data = pd.read_sql(\"select distinct date, sat from bavaria order by date\",conn)\n",
    "    \n",
    "    # add categorical id for easier plotting\n",
    "    data[\"sat_id\"] = data[\"sat\"].astype('category').cat.codes\n",
    "    data.to_csv(fn)\n",
    "    # from file\n",
    "else:\n",
    "    data = pd.read_csv(fn,index_col=0)\n",
    "    \n",
    "dates=data[\"date\"].sort_values()\n",
    "sat=data[\"sat\"].astype(\"category\")\n",
    "#color=scl.sort_index()[\"cloud\"]\n",
    "\n",
    "if type(dates.values[0])==str: #parse to datetime\n",
    "    X = [datetime.strptime(d, '%Y-%m-%d') for d in dates.values]\n",
    "else: # assume already datetime\n",
    "    X = dates.values\n",
    "Y = data[\"sat_id\"]\n",
    "fig, ax = plt.subplots(figsize=(14,1))\n",
    "sc = ax.scatter(X, Y,\n",
    "           marker='o', s=80, edgecolors=\"#000000\", linewidth=.5, alpha=.5, cmap=\"Blues_r\", vmin=0, vmax=1)\n",
    "\n",
    "#cbar = plt.colorbar(sc,aspect=3, ticks=[0, .5, 1])\n",
    "#cbar.ax.set_yticklabels(['0% clouds', '50% clouds', '100 % clouds']) \n",
    "\n",
    "xticks = [datetime(year,month,1) for month in range(1,12,2) for year in [2016,2017]]\n",
    "ax.xaxis.set_ticks(xticks)\n",
    "ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "# everything after this is turning off stuff that's plotted by default\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "monthsFmt = mdates.DateFormatter('%b')\n",
    "yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "# format the ticks\n",
    "ax.xaxis.set_minor_locator(years)\n",
    "ax.xaxis.set_minor_formatter(yearsFmt)\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "ax.xaxis.set_tick_params(which='minor', pad=20)\n",
    "\n",
    "#ax.yaxis.set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "#ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.xaxis.grid(True, which=\"major\")\n",
    "#ax.yaxis.grid()\n",
    "\n",
    "plt.yticks(sat.cat.codes.unique(), sat.cat.categories)\n",
    "\n",
    "plt.xlim(datetime(2015,12,1), datetime(2017,12,31))\n",
    "\n",
    "ax.set_title(\"{} Sentinel 2 A and B observations over 2016 and 2017\".format(len(dates)))\n",
    "\n",
    "plt.ylim(-.5, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Class accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16 =np.load(join(quantevalpath,\"2016\",\"truepred.npy\"))\n",
    "data17 =np.load(join(quantevalpath,\"2017\",\"truepred.npy\"))\n",
    "data = np.vstack((data16,data17))\n",
    "\n",
    "y_true = data[:,0]\n",
    "y_pred = data[:,1]\n",
    "\n",
    "print(skmetrics.classification_report(y_true, y_pred, labels=ids, target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg(y_true,y_pred,function):\n",
    "    micro = function(y_true, y_pred, labels=ids,average='micro')\n",
    "    macro = function(y_true, y_pred, labels=ids,average='macro')\n",
    "    weighted = function(y_true, y_pred, labels=ids,average='weighted')\n",
    "    return micro,macro,weighted\n",
    "\n",
    "dec = 2\n",
    "prec,rec,fscore,sup = skmetrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=ids)\n",
    "\n",
    "avg_prec = skmetrics.precision_score(y_true, y_pred, labels=ids,average='weighted')\n",
    "avg_rec = skmetrics.recall_score(y_true, y_pred, labels=ids,average='weighted')\n",
    "avg_fscore = skmetrics.f1_score(y_true, y_pred, labels=ids,average='weighted')\n",
    "\n",
    "if write_flag:\n",
    "\n",
    "    metrics = np.column_stack((classes,np.around(prec,dec),np.around(rec,dec),np.around(fscore,dec),sup))\n",
    "    with open(join(quantevalpath,\"metrics.csv\"), 'w') as f:\n",
    "        f.write(b'id,name,precision,recall,fscore,support\\n')\n",
    "        np.savetxt(f, metrics, fmt='%s', delimiter=', ', newline='\\n')\n",
    "        f.write(b',,,,,\\n'.format(prec=avg_prec, rec=avg_rec, fsc=avg_fscore))\n",
    "        f.write(b',weight. avg,{prec},{rec},{fsc},\\n'.format(prec=np.around(avg_prec,dec),rec=np.around(avg_rec,dec),fsc=np.around(avg_fscore,dec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = skmetrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#sklearn.metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(cm/cm.max(axis=1).astype(float))\n",
    "axs[0].set_title(\"recall\")\n",
    "\n",
    "cax = axs[1].imshow(cm/cm.max(axis=0).astype(float))\n",
    "axs[1].set_title(\"precision\")\n",
    "cbar = fig.colorbar(cax, ticks=[0, 1], orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = classes\n",
    "\n",
    "import csv\n",
    "\n",
    "def write_flat_cm(confusion_matrix, outfile):\n",
    "    precision = confusion_matrix/(confusion_matrix.sum(axis=0)+1e-10)\n",
    "    recall = confusion_matrix/(confusion_matrix.sum(axis=1)+1e-10)\n",
    "\n",
    "    outcsv = \"\"\n",
    "    rows,columns = confusion_matrix.shape\n",
    "    for c in range(columns):\n",
    "        for r in range(rows):\n",
    "            row=\"{r} {c} {absolute} {precision} {recall}\".format(r=r+1,c=c+1,absolute=int(confusion_matrix[r,c]), precision=precision[r,c], recall=recall[r,c])\n",
    "            outcsv+=row+\"\\n\"\n",
    "\n",
    "    with open(outfile,\"w\") as f:\n",
    "        f.write(outcsv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_flag:\n",
    "\n",
    "    # Absolut\n",
    "    with open(join(quantevalpath,'confusion_matrix_abs.csv'), 'wb') as f:\n",
    "        f.write(\", \".join(classnames)+\"\\n\")\n",
    "        np.savetxt(f, cm, fmt='%d', delimiter=', ', newline='\\n')\n",
    "\n",
    "    # Precision\n",
    "    with open(join(quantevalpath,'confusion_matrix_prec.csv'), 'wb') as f:\n",
    "        f.write(\", \".join(classnames)+\"\\n\")\n",
    "        np.savetxt(f, cm/cm.sum(axis=0).astype(float), fmt='%f', delimiter=', ', newline='\\n')\n",
    "\n",
    "    # Recall\n",
    "    with open(join(quantevalpath,'confusion_matrix_rec.csv'), 'wb') as f:\n",
    "        f.write(\", \".join(classnames)+\"\\n\")\n",
    "        np.savetxt(f, cm/cm.sum(axis=1).astype(float), fmt='%f', delimiter=', ', newline='\\n')\n",
    "\n",
    "    # write these out as flat confusion matrix for tikz pgf plotting...\n",
    "    write_flat_cm(confusion_matrix=cm, outfile=join(quantevalpath,'confusion_matrix_tikz.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write flat confusion matrix for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "filename= 'confusion_matrix.csv'\n",
    "\n",
    "def write_flat_cm(confusion_matrix, outfile):\n",
    "\n",
    "    with open(filename,'r') as f:\n",
    "        header = f.readline()\n",
    "\n",
    "    precision = confusion_matrix/(confusion_matrix.sum(axis=0)+1e-10)\n",
    "    recall = confusion_matrix/(confusion_matrix.sum(axis=1)+1e-10)\n",
    "\n",
    "    outcsv = \"\"\n",
    "    rows,columns = confmat.shape\n",
    "    for c in range(columns):\n",
    "        for r in range(rows):\n",
    "            row=\"{r} {c} {absolute} {precision} {recall}\".format(r=r+1,c=c+1,absolute=int(confmat[r,c]), precision=precision[r,c], recall=recall[r,c])\n",
    "            outcsv+=row+\"\\n\"\n",
    "\n",
    "    with open(outfile,\"w\") as f:\n",
    "        f.write(outcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Class activations of some tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "#model=\"data/bavaria/models/fine_tuned/convlstm256_48px/eval/2017\"\n",
    "tiles = [int(t.split(\".\")[0]) for t in os.listdir(join(qualevalpath,\"2017\",\"ground_truth\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(ax, tileid, folder=\"ground_truth\", title=\"ground truth\",cmap=\"Accent\"):\n",
    "    #im = plt.imread(join(model,folder,str(tileid)+\".tif\"))[:,:,0]\n",
    "    im = Image.open(join(qualevalpath,\"2017\",folder,str(tileid)+\".tif\"))\n",
    "    arr=np.asarray(im)\n",
    "    ax.set_axis_off()\n",
    "    #arr[arr==0]=np.nan\n",
    "    #plt.set_clim(vmin=0, vmax=27)\n",
    "    #cmap=plt.get_cmap(\"gist_earth\")\n",
    "    #print cmap.get_clim()\n",
    "    if cmap=='tum': \n",
    "        colors = tumcolors\n",
    "        rs = np.zeros(arr.shape,dtype=int)\n",
    "        lut = [0]+ids\n",
    "        for i in ids:\n",
    "            np.place(rs, arr==i, lut.index(i))\n",
    "        arr=rs\n",
    "    else: colors = plt.get_cmap(cmap)(np.linspace(0,1,27))\n",
    "    colors[0]=np.array([1,1,1,1])\n",
    "    colored_im = colors[arr]\n",
    "    ax.imshow(colored_im)\n",
    "    ax.set_title(title)\n",
    "    #ax.colorbar()\n",
    "    \n",
    "def plot_activation(ax, tileid, folder=\"loss\", title=\"loss\",vmax=None):\n",
    "    \n",
    "    #ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    #im = plt.imread(join(model,folder,str(tileid)+\".tif\"))[:,:,0]\n",
    "    im = Image.open(join(qualevalpath,\"2017\",folder,str(tileid)+\".tif\"))\n",
    "    #np.asarray(im)\n",
    "    cmap = plt.get_cmap(\"inferno\")\n",
    "    image=cmap(np.asarray(im))\n",
    "    ax.imshow(image, cmap=\"inferno\",vmin=0, vmax=vmax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_tile(tileidx):\n",
    "    tileid=tiles[tileidx]\n",
    "    \n",
    "    fig, axs = plt.subplots(5,4, figsize=(10,12))\n",
    "    \n",
    "    \n",
    "    plt.suptitle('Tile '+(str(tileid)))\n",
    "    \n",
    "    #axs = [ax for ax in ax_row for ax_row in axs]\n",
    "    axs_list=list()\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            axs_list.append(ax)\n",
    "\n",
    "    plot_class(axs_list.pop(0),tileid, folder=\"ground_truth\", title=\"ground truth\",cmap=\"tum\")\n",
    "    plot_class(axs_list.pop(0),tileid, folder=\"prediction\", title=\"prediction\",cmap=\"tum\")\n",
    "    plot_activation(axs_list.pop(0),tileid, folder=\"loss\", title=\"loss\",vmax=1)\n",
    "\n",
    "    flds = [\"1_sugar_beet\",\"2_summer_oat\",\"3_meadow\",\"4_rape\",\"5_hop\",\"6_winter_spelt\",\"7_winter_triticale\",\"8_beans\",\"9_peas\",\n",
    "    \"10_potatoe\",\"11_soybeans\",\"12_asparagus\",\"13_winter_wheat\",\"14_winter_barley\",\"15_winter_rye\",\"16_summer_barley\",\"17_maize\"]\n",
    "\n",
    "    names=[\" \".join(el.split(\"_\")[1:]) for el in flds]\n",
    "\n",
    "    #plot_activation(axs_list[0],tileid, folder=\"confidences/\"+flds[0], title=names[0])\n",
    "    #plot_activation(axs_list[1],tileid, folder=\"confidences/\"+flds[1], title=names[1])\n",
    "    #plot_activation(axs_list[2],tileid, folder=\"confidences/\"+flds[2], title=names[2])\n",
    "    for fld,name in zip(flds,names):\n",
    "        plot_activation(axs_list.pop(0),tileid, folder=\"confidences/\"+fld, title=name,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "plot_class(ax, 10969, folder=\"ground_truth\", title=\"ground truth\",cmap=\"tum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(tiles)-1,\n",
    "    step=1,\n",
    "    description='Tile:'\n",
    ")\n",
    "interact(plot_tile,tileidx=tile_slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MTLCC]",
   "language": "python",
   "name": "conda-env-MTLCC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
